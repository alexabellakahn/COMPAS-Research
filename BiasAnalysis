# Download dataset
!wget -q --show-progress "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Projects%20-%20AI%20and%20Ethics%20-%20Criminal%20Justice/compas-scores-two-years.csv"

# Import libraries
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import ConfusionMatrixDisplay

# Load and clean data
data = pd.read_csv("compas-scores-two-years.csv")
columns_to_drop = [
    'id', 'name', 'first', 'last', 'compas_screening_date', 'dob', 'days_b_screening_arrest',
    'c_jail_in', 'c_jail_out', 'c_case_number', 'c_offense_date', 'c_arrest_date', 
    'c_days_from_compas', 'r_case_number', 'r_charge_degree', 'r_days_from_arrest', 
    'r_offense_date', 'r_charge_desc', 'r_jail_in', 'r_jail_out', 'vr_case_number', 
    'vr_charge_degree', 'vr_offense_date', 'decile_score.1', 'violent_recid', 'vr_charge_desc', 
    'in_custody', 'out_custody', 'priors_count.1', 'start', 'end', 'v_screening_date', 'event', 
    'type_of_assessment', 'v_type_of_assessment', 'screening_date', 'score_text', 'v_score_text', 
    'v_decile_score', 'decile_score', 'is_recid', 'is_violent_recid'
]
df = data.drop(columns=columns_to_drop)
df.columns = [
    'sex', 'age', 'age_category', 'race', 'juvenile_felony_count', 'juvenile_misdemeanor_count', 
    'juvenile_other_count', 'prior_convictions', 'current_charge', 'charge_description', 
    'recidivated_last_two_years'
]

# Filter out rare charges
value_counts = df['charge_description'].value_counts()
df = df[df['charge_description'].isin(value_counts[value_counts >= 70].index)].reset_index(drop=True)

# One-hot encode categorical variables
for colname in df.select_dtypes(include='object').columns:
    one_hot = pd.get_dummies(df[colname], prefix=colname)
    df = pd.concat([df.drop(colname, axis=1), one_hot], axis=1)

# Split data into train and test sets
y_column = 'recidivated_last_two_years'
X_all, y_all = df.drop(y_column, axis=1), df[y_column]
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3, random_state=1)

# Split data for race-specific evaluations
X_caucasian = X_test[X_test['race_Caucasian'] == 1]
y_caucasian = y_test[X_test['race_Caucasian'] == 1]
X_african_american = X_test[X_test['race_African-American'] == 1]
y_african_american = y_test[X_test['race_African-American'] == 1]

# Logistic Regression
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
print("Logistic Regression Training Accuracy:", model.score(X_train, y_train))
print("Logistic Regression Testing Accuracy:", model.score(X_test, y_test))

# SVM Model
from sklearn import svm
model_svm = svm.SVC(kernel='linear')
model_svm.fit(X_train, y_train)
print("SVM Training Accuracy:", model_svm.score(X_train, y_train))
print("SVM Testing Accuracy:", model_svm.score(X_test, y_test))

# Feature importances for SVM
importance_svm = model_svm.coef_[0]
features = X_all.columns
plt.bar(features, importance_svm)
plt.xticks(rotation="vertical", fontsize=10)
plt.xlabel("Feature")
plt.ylabel("Coefficient Value")
plt.title("SVM Feature Importances")
plt.show()

# Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
model_rf = RandomForestClassifier(max_depth=5, random_state=1)
model_rf.fit(X_train, y_train)
print("Random Forest Training Accuracy:", model_rf.score(X_train, y_train))
print("Random Forest Testing Accuracy:", model_rf.score(X_test, y_test))

# Feature importances for Random Forest
rf_importances = model_rf.feature_importances_
plt.bar(features, rf_importances)
plt.xticks(rotation="vertical", fontsize=10)
plt.xlabel("Feature")
plt.ylabel("Importance")
plt.title("Random Forest Feature Importances")
plt.show()

# Race-specific feature importances
race_features = features[-6:]  # Adjust based on encoding order
race_importances = rf_importances[-6:]
plt.bar(race_features, race_importances)
plt.xlabel("Race Features")
plt.ylabel("Importance")
plt.title("Race-Specific Feature Importances")
plt.show()

# Neural Network
from sklearn.neural_network import MLPClassifier
model_nn = MLPClassifier(hidden_layer_sizes=(100, 50, 25), random_state=1, max_iter=500)
model_nn.fit(X_train, y_train)
print("Neural Network Training Accuracy:", model_nn.score(X_train, y_train))
print("Neural Network Testing Accuracy:", model_nn.score(X_test, y_test))
